{
    "creditHours": "4 hours", 
    "endDate": "2017-05-03-05:00", 
    "enrollmentStatus": "Open (Restricted)", 
    "href": "/2017/spring/ME/598/65801.json", 
    "id": "65801", 
    "meetings": {
        "meeting": {
            "daysOfTheWeek": "MW", 
            "end": "12:50 PM", 
            "id": "0", 
            "instructors": {
                "instructor": {
                    "content": "Dullerud, G", 
                    "firstName": "G", 
                    "lastName": "Dullerud"
                }
            }, 
            "start": "11:00 AM", 
            "type": {
                "code": "LEC", 
                "content": "Lecture"
            }
        }
    }, 
    "parents": {
        "calendarYear": {
            "content": "2017", 
            "href": "/2017.json", 
            "id": "2017"
        }, 
        "course": {
            "content": "Special Topics", 
            "href": "/2017/spring/ME/598.json", 
            "id": "598"
        }, 
        "subject": {
            "content": "Mechanical Engineering", 
            "href": "/2017/spring/ME.json", 
            "id": "ME"
        }, 
        "term": {
            "content": "Spring 2017", 
            "href": "/2017/spring.json", 
            "id": "120171"
        }
    }, 
    "partOfTerm": "1", 
    "sectionNotes": "Restricted to Graduate - Urbana-Champaign.", 
    "sectionNumber": "GD", 
    "sectionStatusCode": "A", 
    "sectionText": "The course is aimed at broadening student knowledge of theory and applications in stochastic methods for estimation and control.  It will introduce and investigate a range of topics in this area, and does not assume strong familiarity with probabilistic methods. In additional to fundamentals, it will feature a variety of applications including:  automatic control and robotics, supply-chain optimization,  finance,  and dynamic resource allocation.   Topics covered will  be statistical inference for discrete and continuous random variables. Linear estimation with Gaussian noise. Markov decision processes, optimal policy with full state information for finite-horizon case, infinite-horizon discounted, and average stage cost problems. Bellman value function, value iteration, and policy iteration. Approximate dynamic programming. Linear quadratic stochastic control.  Example lectures: Random variables, estimation and prediction classification, continuous random vectors, recursive estimation, Kalman filter, regression and learning, probability and Monte Carlo, Markov chains, hitting times, structure of Markov chains, Markov decision processes, the Bellman-Ford algorithm, model predictive control, shortest paths, informed search, risk averse control, linear exponential quadratic regulator, hidden Markov models.", 
    "sectionTitle": "Estimation & Stochastic Cntrl", 
    "startDate": "2017-01-17-06:00", 
    "statusCode": "A"
}